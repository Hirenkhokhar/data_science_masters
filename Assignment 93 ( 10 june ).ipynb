{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b04c9576",
   "metadata": {},
   "source": [
    "## Part 1:  Understanding_Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f7e970",
   "metadata": {},
   "source": [
    "<b>Q1 What is the role of optimization algorithms in artificial neural networks? Why are they necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb10cd3",
   "metadata": {},
   "source": [
    "Optimization algorithms play a crucial role in training artificial neural networks (ANNs). The primary goal of training a neural network is to adjust its parameters (weights and biases) in such a way that it can accurately map input data to desired output. Optimization algorithms are necessary for achieving this goal by minimizing the error or loss between the predicted outputs of the network and the actual target outputs. Here's why optimization algorithms are essential in the context of neural networks:\n",
    "\n",
    "Parameter Tuning: Neural networks typically consist of a large number of parameters that determine how the network transforms input data. Optimization algorithms iteratively adjust these parameters during training to find the optimal values that lead to better performance on the task at hand.\n",
    "\n",
    "Loss Minimization: The primary objective of training a neural network is to minimize a loss function that quantifies the difference between the predicted outputs and the actual target outputs. Optimization algorithms work to find parameter values that minimize this loss, effectively improving the network's accuracy.\n",
    "\n",
    "High-Dimensional Optimization: Neural networks often have a high-dimensional parameter space. Finding the optimal set of parameters in such a space can be extremely challenging. Optimization algorithms provide systematic and efficient ways to navigate this complex space and converge to a solution.\n",
    "\n",
    "Non-Convex Optimization: The loss function in neural networks is generally non-convex, meaning it has multiple local minima and maxima. Optimization algorithms aim to find a good solution even in the presence of such complex landscapes.\n",
    "\n",
    "Stochastic Gradient Descent (SGD): This is one of the most commonly used optimization algorithms for training neural networks. SGD and its variants work by computing gradients of the loss with respect to the parameters using a subset of the training data (mini-batch) and adjusting the parameters in the direction that reduces the loss.\n",
    "\n",
    "Adaptation to Data: Optimization algorithms allow the neural network to adapt to the specifics of the training data. As the network encounters more examples, the optimization process refines the parameters, making the network generalize better to unseen data.\n",
    "\n",
    "Regularization and Generalization: Some optimization algorithms incorporate regularization techniques to prevent overfitting. Regularization helps the network learn patterns in the data rather than memorizing it, leading to improved generalization to new data.\n",
    "\n",
    "Hyperparameter Optimization: Neural networks have hyperparameters (learning rate, batch size, etc.) that are not learned during training. Optimization algorithms also play a role in finding suitable values for these hyperparameters, impacting the training process.\n",
    "\n",
    "In summary, optimization algorithms are necessary to train neural networks effectively and efficiently. They guide the network's parameter adjustments toward minimizing the loss function, navigating through high-dimensional and non-convex spaces, and adapting the network to the underlying data distribution. The choice of optimization algorithm and its parameters can significantly impact the training process and the final performance of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb26c8",
   "metadata": {},
   "source": [
    "<b>Q2 Explain the concept of gradient descent and its variants. Discuss their differences and tradeoffs in terms\n",
    "of convergence speed and memory and reuirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cda8f8",
   "metadata": {},
   "source": [
    "Gradient Descent is a fundamental optimization technique used to minimize a function, typically a loss function in the context of machine learning, by iteratively adjusting the parameters in the direction of the steepest descent (opposite to the gradient). There are several variants of Gradient Descent, each with its own characteristics, trade-offs, and impact on convergence speed and memory requirements. Let's explore some of these variants:\n",
    "\n",
    "Batch Gradient Descent (BGD):\n",
    "\n",
    "In BGD, the entire training dataset is used to compute the gradient of the loss function with respect to the parameters in each iteration.\n",
    "It provides accurate gradient estimates but can be computationally expensive, especially for large datasets.\n",
    "BGD has stable convergence and smooth parameter updates.\n",
    "Stochastic Gradient Descent (SGD):\n",
    "\n",
    "SGD computes the gradient and updates the parameters using only one randomly selected training example in each iteration.\n",
    "It can lead to faster convergence due to more frequent parameter updates, but the updates can be noisy, resulting in oscillations around the optimal solution.\n",
    "SGD has lower memory requirements as it processes one example at a time.\n",
    "Mini-Batch Gradient Descent:\n",
    "\n",
    "Mini-Batch GD strikes a balance between BGD and SGD by using a small subset (mini-batch) of the training data for gradient computation and parameter updates.\n",
    "It combines the advantages of both methods: faster convergence than BGD and more stable updates than SGD.\n",
    "The mini-batch size is a hyperparameter that needs to be tuned.\n",
    "Gradient Descent with Momentum:\n",
    "\n",
    "Momentum introduces a \"velocity\" term that accumulates a fraction of the past gradients' direction.\n",
    "This helps to smooth out the updates and prevent oscillations, particularly in the presence of noisy gradients.\n",
    "It accelerates convergence, especially in flat or narrow regions of the loss landscape.\n",
    "Adaptive Learning Rate Methods (e.g., AdaGrad, RMSProp, Adam):\n",
    "\n",
    "These methods adapt the learning rate for each parameter based on their historical gradients.\n",
    "AdaGrad scales down the learning rate for frequently updated parameters, allowing slower convergence along steep dimensions.\n",
    "RMSProp and Adam combine the benefits of momentum and adaptive learning rates for faster convergence and robustness.\n",
    "Trade-offs and Comparisons:\n",
    "\n",
    "Convergence Speed: In general, methods like SGD and its variants converge faster compared to traditional BGD, especially for large datasets, due to more frequent updates. Adaptive learning rate methods like Adam can further enhance convergence speed by adjusting learning rates based on past gradients.\n",
    "\n",
    "Memory Requirements: BGD requires more memory as it computes gradients using the entire dataset in each iteration. SGD and mini-batch methods have lower memory requirements since they process smaller subsets. Adaptive methods maintain additional information (like gradient accumulators), which can increase memory usage.\n",
    "\n",
    "Stability and Noise: BGD provides a stable gradient estimate but can be slow. SGD can be noisy due to its use of single examples, potentially leading to oscillations. Mini-batch methods offer a compromise between stability and speed. Momentum and adaptive methods help mitigate noise and stabilize updates.\n",
    "\n",
    "Hyperparameters: Different variants have hyperparameters to tune, such as learning rates, momentum coefficients, and mini-batch sizes. The choice of these hyperparameters can impact convergence behavior and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc71168c",
   "metadata": {},
   "source": [
    "<b>Q3 Describe the challenges associated with traditional gradient descent optimization methods (e.g., slow\n",
    "convergence, local minima ). How do modern optimizers address these challenges ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb6f504",
   "metadata": {},
   "source": [
    "Traditional gradient descent optimization methods, such as Batch Gradient Descent (BGD), suffer from several challenges that can hinder their efficiency and effectiveness in training machine learning models. Modern optimizers have been developed to address these challenges and improve the convergence and performance of optimization algorithms. Here are some challenges associated with traditional gradient descent methods and how modern optimizers tackle them:\n",
    "\n",
    "Slow Convergence:\n",
    "\n",
    "Challenge: BGD computes gradients using the entire training dataset, which can be computationally expensive and lead to slow convergence, especially for large datasets.\n",
    "Solution: Modern optimizers introduce techniques that update parameters more frequently, leading to faster convergence. Stochastic Gradient Descent (SGD) and mini-batch variants update parameters using smaller subsets of data, allowing more iterations within a fixed time frame, which often accelerates convergence.\n",
    "Local Minima and Plateaus:\n",
    "\n",
    "Challenge: Traditional gradient descent methods can get trapped in local minima or plateaus (flat regions of the loss landscape) and struggle to escape them.\n",
    "Solution: Modern optimizers incorporate momentum or adaptive learning rate mechanisms. Momentum helps the optimizer overcome local minima by accumulating past gradients' directions, allowing it to navigate flat regions more effectively. Adaptive methods, such as Adam and RMSProp, adjust the learning rate based on the gradient history, which helps the optimizer escape plateaus and find faster convergence paths.\n",
    "Oscillations and Noisy Gradients:\n",
    "\n",
    "Challenge: SGD can produce noisy updates due to the use of individual training examples. This noise can lead to oscillations and hinder convergence.\n",
    "Solution: Optimizers like momentum and adaptive methods provide smoother updates by considering past gradient information. Momentum dampens oscillations by incorporating past velocity information, while adaptive methods adapt learning rates to the gradient history, mitigating the impact of noisy gradients.\n",
    "Choosing Appropriate Learning Rates:\n",
    "\n",
    "Challenge: Setting an appropriate learning rate is crucial for convergence. Too large a learning rate can lead to overshooting, divergence, or erratic behavior, while too small a learning rate can slow down convergence.\n",
    "Solution: Modern optimizers often include adaptive learning rate mechanisms. Adaptive methods adjust the learning rate based on the history of gradient magnitudes. This allows the optimizer to automatically decrease the learning rate for rapidly changing parameters and increase it for slowly changing ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2085b4c",
   "metadata": {},
   "source": [
    "<b>Q4 Discuss the concepts of momentum and learning rate in the context of optimization algorithms. How do\n",
    "they impact convergence and model performance ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e990e",
   "metadata": {},
   "source": [
    "<b>Momentum:\n",
    "\n",
    "Momentum is a technique used to enhance the gradient descent optimization process by introducing a \"velocity\" term that helps the optimization algorithm overcome obstacles such as local minima, narrow valleys, and noisy gradients. The basic idea is to accumulate a fraction of the past gradients' directions and use this accumulated direction to guide the parameter updates.\n",
    "\n",
    "Impact of Momentum:\n",
    "Momentum helps in accelerating convergence and mitigating the oscillations that can occur during optimization. Here's how it impacts convergence and model performance:\n",
    "\n",
    "Faster Convergence: Momentum enables the optimization algorithm to \"carry forward\" the previous directions of gradients, which helps it move more confidently and quickly through areas of shallow gradients or flat regions.\n",
    "\n",
    "Escape from Local Minima: The accumulated momentum term can help the algorithm escape local minima and continue to explore the parameter space, increasing the likelihood of finding a better solution.\n",
    "\n",
    "Dampening Oscillations: By averaging the direction of past gradients, momentum dampens the oscillations that can occur when gradients are noisy or erratic.\n",
    "\n",
    "Smoothing Updates: Momentum smooths out the parameter updates, leading to more stable convergence trajectories.\n",
    "\n",
    "<b>Learning Rate:\n",
    "\n",
    "The learning rate is a hyperparameter that determines the step size of parameter updates during optimization. It controls how large each step is in the direction of the gradient. A high learning rate allows for faster convergence, but it can also lead to overshooting the optimal solution and potentially diverging. A low learning rate provides more stability but may lead to slow convergence or getting stuck in local minima.\n",
    "\n",
    "Impact of Learning Rate:\n",
    "The learning rate has a significant impact on the optimization process and model performance:\n",
    "\n",
    "Convergence Speed: A higher learning rate accelerates convergence by allowing larger step sizes. However, if the learning rate is too high, the optimization process might overshoot the optimal solution, leading to instability.\n",
    "\n",
    "Stability: A lower learning rate provides more stable updates, reducing the risk of overshooting or diverging. It is particularly useful in fine-tuning the optimization process when the model is close to convergence.\n",
    "\n",
    "Hyperparameter Sensitivity: The choice of learning rate is crucial and can be problem-dependent. Finding an appropriate learning rate often requires experimentation.\n",
    "\n",
    "Learning Rate Scheduling: Some optimization algorithms use learning rate schedules, where the learning rate changes over time (e.g., decreases gradually). This can help balance fast progress in the beginning with more stable convergence towards the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12e5d0",
   "metadata": {},
   "source": [
    "## Part 2: Optimiaer Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722b5e6",
   "metadata": {},
   "source": [
    "<B>Q5 Explain the concept of Stochastic radient Descent (SGD) and its advantages compared to traditional\n",
    "gradient descent. Discuss its limitations and scenarios where it is most suitable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355dcac",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent (SGD) is an optimization algorithm used to train machine learning models, particularly neural networks. It is a variant of the traditional gradient descent algorithm that addresses some of the limitations associated with the latter. In SGD, instead of computing the gradient of the loss function using the entire training dataset (as in Batch Gradient Descent), the gradient is computed using only one randomly selected training example at a time. This introduces a level of randomness and noise into the gradient estimation.\n",
    "\n",
    "Advantages of Stochastic Gradient Descent:\n",
    "\n",
    "Faster Updates: Because SGD processes one training example at a time, it updates the model parameters more frequently than Batch Gradient Descent. This faster update frequency often leads to faster convergence.\n",
    "\n",
    "Memory Efficiency: SGD requires significantly less memory as it operates on individual examples instead of the entire dataset. This is particularly advantageous when working with large datasets that might not fit entirely in memory.\n",
    "\n",
    "Generalization: The noise introduced by using individual examples can help the optimization process to escape shallow local minima and explore different directions, potentially leading to better generalization and finding better solutions.\n",
    "\n",
    "Stochastic Nature: The inherent randomness in SGD allows it to jump around the parameter space, which can help it overcome plateau regions and avoid getting stuck in poor solutions.\n",
    "\n",
    "Online Learning: SGD's ability to learn from each individual example makes it suitable for scenarios where the data distribution changes over time. It is commonly used in online and streaming learning settings.\n",
    "\n",
    "Limitations and Scenarios:\n",
    "\n",
    "Noisy Updates: The stochastic nature of SGD introduces noise into the parameter updates, which can lead to oscillations and slow convergence, especially in the early stages of training.\n",
    "\n",
    "Irregular Convergence: Due to its inherent randomness, SGD doesn't have a consistent or predictable trajectory in terms of convergence. This can make it harder to tune hyperparameters and track progress.\n",
    "\n",
    "Vulnerable to Local Minima: While SGD's noise can help escape some local minima, it might also lead the optimization process into other local minima due to the randomness of updates.\n",
    "\n",
    "Learning Rate Tuning: The learning rate in SGD becomes a crucial hyperparameter that needs careful tuning. Too high a learning rate can lead to divergence, while too low a learning rate can result in slow convergence.\n",
    "\n",
    "Mini-Batch SGD: In practice, a compromise between pure SGD and Batch Gradient Descent is often used: mini-batch SGD. It involves computing gradients over small subsets of data (mini-batches), which provides a balance between the advantages of both methods.\n",
    "\n",
    "Suitable Scenarios for SGD:\n",
    "\n",
    "Large Datasets: When working with large datasets, SGD's memory efficiency becomes a significant advantage, as it allows training without requiring the entire dataset to fit in memory.\n",
    "Non-Convex Optimization: In complex optimization landscapes, SGD's ability to explore different directions can help it find satisfactory solutions in non-convex scenarios.\n",
    "Online Learning: In scenarios where new data is continually arriving, such as real-time analysis, SGD's ability to learn from individual examples in an online fashion is highly useful.\n",
    "In summary, SGD offers advantages in terms of faster updates, memory efficiency, and potential for better generalization. However, its stochastic nature introduces noise and can lead to irregular convergence. It's most suitable for scenarios involving large datasets, non-convex optimization, and online learning, but hyperparameter tuning remains critical.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd74c94",
   "metadata": {},
   "source": [
    "<b>Q6 Describe the concept of Adam optimizer and how it combines momentum and adaptive learning rates.\n",
    "Discuss its benefits and potential drawbacks ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a957a07",
   "metadata": {},
   "source": [
    "\n",
    "The Adam optimizer (short for Adaptive Moment Estimation) is a popular optimization algorithm used to train machine learning models, especially neural networks. It combines the concepts of momentum and adaptive learning rates to provide efficient and effective parameter updates during optimization. Adam is designed to address some of the limitations of other optimization methods, such as choosing appropriate learning rates and handling noisy or sparse gradients.\n",
    "\n",
    "Concept of Adam Optimizer:\n",
    "\n",
    "Adam maintains two moving averages: the first moment (mean of the gradients) and the second moment (uncentered variance of the gradients). These moving averages are then used to adjust the learning rate for each parameter during optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc60c8",
   "metadata": {},
   "source": [
    "Benefits of Adam Optimizer:\n",
    "\n",
    "Adaptive Learning Rates: Adam adjusts the learning rate for each parameter based on the historical first and second moment estimates. This adaptive nature helps prevent the need for meticulous learning rate tuning and allows the optimizer to navigate different areas of the parameter space effectively.\n",
    "\n",
    "Combination of Momentum and Adaptive Learning Rates: Adam combines the benefits of momentum (first moment) and adaptive learning rates (second moment) in a single optimization algorithm. This combination accelerates convergence and enhances stability.\n",
    "\n",
    "Efficiency: The adaptive learning rate mechanism of Adam allows it to converge faster than methods with fixed learning rates, especially in scenarios where the optimal learning rate varies across dimensions.\n",
    "\n",
    "Robustness to Sparse Gradients: Adam's adaptive learning rates make it suitable for scenarios with sparse gradients, where traditional methods like SGD might struggle to converge effectively.\n",
    "\n",
    "Drawbacks and Considerations:\n",
    "\n",
    "Hyperparameter Sensitivity: While Adam reduces the need for extensive learning rate tuning, it still has hyperparameters (\n",
    "β \n",
    "1, \n",
    "β \n",
    "2, \n",
    "ϵ) that need to be set. Incorrect hyperparameter values can lead to suboptimal convergence.\n",
    "\n",
    "Noisy Updates: Adam's adaptive learning rates can sometimes lead to noisy updates, especially when dealing with small batch sizes. This might require tuning of the hyperparameters to mitigate the noise.\n",
    "\n",
    "Convergence to Flat Minima: Some studies suggest that Adam might converge to flat minima, resulting in models that generalize less effectively. This depends on the problem and model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991973ef",
   "metadata": {},
   "source": [
    "<b>Q7 Explain the concept of RMSprop optimizer and how it addresses the challenges of adaptive learning\n",
    "rates. ompare it with Adam and discuss their relative strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b3bb4",
   "metadata": {},
   "source": [
    "\n",
    "The RMSprop optimizer (short for Root Mean Square Propagation) is an adaptive optimization algorithm designed to address some of the challenges associated with learning rates in gradient descent optimization. It is particularly effective in scenarios where the magnitudes of the gradients vary significantly across different dimensions or time steps. RMSprop adapts the learning rates for individual parameters based on the historical magnitudes of the gradients.\n",
    "\n",
    "Benefits of RMSprop Optimizer:\n",
    "\n",
    "Adaptive Learning Rates: RMSprop adapts the learning rates for each parameter based on the historical squared gradients. It mitigates the need for manual learning rate tuning and improves convergence in scenarios with varying gradient magnitudes.\n",
    "\n",
    "Robustness to Sparse Gradients: RMSprop's adaptive learning rates make it suitable for problems with sparse gradients, where traditional methods might converge slowly or struggle.\n",
    "\n",
    "Stability: By using squared gradients, RMSprop can prevent overly aggressive updates that can lead to divergence or oscillations.\n",
    "\n",
    "Comparison with Adam Optimizer:\n",
    "\n",
    "Both RMSprop and Adam are adaptive optimization algorithms that address the challenges of learning rates, but they differ in their approaches:\n",
    "\n",
    "RMSprop: RMSprop adapts the learning rates using a moving average of squared gradients. It has one hyperparameter (β) that controls the decay rate of the moving average.\n",
    "\n",
    "Adam: Adam also adapts learning rates based on the first and second moments of the gradients, but it combines momentum (first moment) and adaptive learning rates (second moment). It has two hyperparameters (β \n",
    "1\n",
    " and\n",
    "β \n",
    "2) that control the decay rates of the moving averages and an additional hyperparameter \n",
    "ϵ) to prevent division by zero.\n",
    "\n",
    "Strengths and Weaknesses:\n",
    "\n",
    "RMSprop:\n",
    "\n",
    "Strengths:\n",
    "Simplicity: RMSprop has fewer hyperparameters than Adam, making it easier to tune.\n",
    "Effective: RMSprop can be effective in optimizing a wide range of problems, especially when gradients vary across dimensions.\n",
    "Weaknesses:\n",
    "Lack of Momentum: RMSprop doesn't have a momentum term, which can result in slower convergence when compared to methods with momentum.\n",
    "Adam:\n",
    "\n",
    "Strengths:\n",
    "Momentum: Adam incorporates momentum, which can help accelerate convergence and navigate flat or rugged loss landscapes.\n",
    "Adaptive Learning Rates: The combination of momentum and adaptive learning rates can make Adam more versatile in terms of convergence speed and robustness.\n",
    "Weaknesses:\n",
    "Hyperparameter Sensitivity: Adam has more hyperparameters to tune, making it potentially more complex to configure properly.\n",
    "Potential for Noisy Updates: The combination of momentum and adaptive learning rates in Adam might introduce noise in certain cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3648a12",
   "metadata": {},
   "source": [
    "## Part 3: Applying Optimizers`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35b2b5",
   "metadata": {},
   "source": [
    "<b>Q8 Implement SGD, Adam, and RMSprop optimizers in a deep learning model using a framework of your\n",
    "choice. Train the model on a suitable dataset and compare their impact on model convergence and\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6755f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense , Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed97a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "084e8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024ab1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(128,activation= 'relu'))\n",
    "model.add(Dense(10,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3e297",
   "metadata": {},
   "source": [
    "## Optimizers  = SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad46641",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',optimizer = 'SGD',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2613c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0811 - val_accuracy: 0.9795\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0801 - val_accuracy: 0.9800\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0793 - val_accuracy: 0.9805\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0790 - val_accuracy: 0.9803\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0791 - val_accuracy: 0.9807\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.0792 - val_accuracy: 0.9806\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0792 - val_accuracy: 0.9805\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.0793 - val_accuracy: 0.9806\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0794 - val_accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0795 - val_accuracy: 0.9805\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1135311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 962us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9815"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = model.predict(X_test)\n",
    "y_pred = y_prob.argmax(axis= 1)\n",
    "y_pred\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a520a7",
   "metadata": {},
   "source": [
    "## Optimizers = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c7b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',optimizer = 'Adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c9c9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.0953 - val_accuracy: 0.9770\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.1009 - val_accuracy: 0.9762\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0916 - val_accuracy: 0.9775\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0999 - val_accuracy: 0.9756\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1028 - val_accuracy: 0.9769\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1156 - val_accuracy: 0.9757\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1054 - val_accuracy: 0.9774\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1375 - val_accuracy: 0.9723\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1238 - val_accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1365 - val_accuracy: 0.9745\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1a99cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 904us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9762"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = model.predict(X_test)\n",
    "y_pred = y_prob.argmax(axis= 1)\n",
    "y_pred\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abc047",
   "metadata": {},
   "source": [
    "## optimizer = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4264b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',optimizer = 'RMSprop',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0dda25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1150 - val_accuracy: 0.9793\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 4.4127e-04 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9798\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.2901e-04 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9803\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 1.5981e-04 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9806\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 1.1965e-04 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9808\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 9.3073e-05 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9809\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 7.6502e-05 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9808\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 6.5405e-05 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9808\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 5.8693e-05 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9803\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 5.1505e-05 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b80f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 933us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9812"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = model.predict(X_test)\n",
    "y_pred = y_prob.argmax(axis= 1)\n",
    "y_pred\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276d5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
